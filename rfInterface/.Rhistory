X <- as.Date(range(series))
Xseq <- seq(X[1], X[2], by='month')
Xlen <- findInterval(length(Xseq), c(0,12,36,60))
Xseq <- switch(Xlen,
seq(X[1], X[2], by='month'),
seq(X[1], X[2], by='3 months'),
seq(X[1], X[2], by='6 months'),
seq(X[1], X[2], by='year'))
Xlab <- switch(Xlen,
"%b %Y","%b %Y","%b %Y","%Y")
graphics::axis(1, at=Xseq, labels=format(Xseq, Xlab), ...)
graphics::axis(1, at=seq(X[1], X[2], by='month'), labels=F, tick=T)
}
autoaxis(dt)
autoAxis(dt)
xt <- (arima.sim(list(order=c(3,0,0), ar=c(0.5,0.25,0.125)), n=100) + 2)^2
dt <- as.Date(1:100, origin="2000-01-01")
potx <- ilaprosUtils::extractPeaks(1:100,xt,2,(2/3))
poty <- extractPeaksMod(dt,xt,2,(2/3), threshold=quantile(xt, 0.9))
all(potx==poty$is_peak)
plot(dt,xt, type='l', xaxt='n')
points(dt[potx==1], xt[potx==1], col='blue', pch=3)
points(dt[poty$is_peak==1], xt[poty$is_peak==1], col='red', pch=2)
points(poty$pot$time, poty$pot$obs, col="green", pch=4)
abline(h=quantile(xt,0.9), col="grey50", lty=2)
autoAxis(dt)
library(rfInterface)
library(rfInterface)
library(rfInterface)
devtools::document()
devtools::document()
library(rfInterface)
devtools::check(cleanup = FALSE,args = c('--no-examples'),manual = TRUE,path = getwd())
?check
check(manual=T)
devtools::check(manual=T)
build_manual()
devtools::build_manual()
library(rfInterface)
?POTextract
library(rfInterface)
?POTextract
library(rfInterface)
devtools::document()
current.session()
library(rfInterface)
?POTextract
library(rfInterface)
devtools::document()
devtools::build_manual()
devtools::document()
devtools::build_manual()
?pastecs
library(pastecs)
library(trend)
xt <- (arima.sim(list(order=c(3,0,0), ar=c(0.5,0.25,0.125)), n=100) + 2)^2
dt <- as.Date(1:100, origin="2000-01-01")
mk.test(xt)
plot(dt,xt, type='l', xaxt='n')
mmkk <- mk.test(xt)
mmkk$p.value
mmkk$parameter
mmkk$statistic
mmkk$null.value
mmkk$method
mmkk$estimates
plot(dt,xt, type='l', xaxt='n')
rfInterface:::import_ts(ids="SX67F051", org="EA", dat="gdf", metadata=T)
ra <- rfInterface:::import_ts(ids="SX67F051", org="EA", dat="gdf", metadata=T)
devtools::document()
devtools::build_manual()
stationList("COSMOS")
devtools::document()
devtools::document()
stationList("COSMOS")
devtools::document()
library(rfInterface)
?rfInterface
devtools::document()
devtools::build_manual()
gdf_fetch <- jsonlite::fromJSON(
txt=paste0("https://gateway-staging.ceh.ac.uk/hydrology-ukscape/stations/",
"EA/gdf/723a8fc4-908b-4430-91c7-9990be86540a/1900-01-01/1901-01-01"),
simplifyDataFrame=T)
site_fetch <- jsonlite::fromJSON(
txt="https://gateway-staging.ceh.ac.uk/hydrology-ukscape/stations",
simplifyDataFrame=T)
lookup_fetch <- jsonlite::fromJSON(
txt="https://gateway-staging.ceh.ac.uk/hydrology-ukscape/lookup",
simplifyDataFrame=T)
?exists
exists(lookup_fetch)
exists("lookup_fetch")
install.packages("pastecs")#
library(pastecs)
install.packages("rnrfa")
library(rnrfa)
plot_rain_flow(34034)
plot_rain_flow(id = 54090)
plot_rain_flow(id = 25018)
library(rfInterface)
SF <- site_fetch$data[[1]]
View(SF)
SF <- site_fetch$data[[2]]
plot(SF$latitude, SF$longitude)
plot(SF$longitude, SF$latitude)
devtools::check(document=TRUE)
source('~/UKSCAPE_C/flowAPIpackage/rfInterface/R/hello.R')
library(rfInterface)
rp <- c(5,10,25,100)
1/(1-rp)
1 - (1/rp)
df <- data.frame(x=1, y=2)
df <- dataframe(x=1, y=2)
df <- dataFrame(x=1, y=2)
dnorm(0.95)
qnorm(0.95)
qnorm(0.975)
qnorm(1- 0.5*(1-0.95))
qnorm(1- 0.5*(1-0.99))
qnorm(1- 0.5*(1-0.68))
qnorm(1- 0.5*(1-0.995))
M <- matrix(1:8, 4, 2)
M
M[5] <- NA
M
M[7] <- NA
M
na.trim(M)
zoo::na.trim(M)
MM <- zoo::na.trim(M)
M[2] <- NA
zoo::na.trim(M)
shiny::runApp('~/UKSCAPE_C/nrfa-trend-shiny/nrfa_trend1')
library(devtools)
devtools::check(rfInterface)
check
?check
getwd()
check()
check()
pretty_breaks(1,7)
scales::pretty_breaks(1,7)
scales::pretty_breaks(1,7)(1,7)
scales::pretty_breaks(7)
scales::pretty_breaks(7)(1,10)
scales::pretty_breaks(7)(7)
scales::pretty_breaks(7)(c(1,10))
scales::pretty_breaks(7)(c(1,20))
scales::pretty_breaks(7)(c(1,30))
breaks(7)(c(1,30))
pretty(7)(c(1,30))
pretty(c(1,30), 7)
f <- function(x){pretty(x,7)}
f(c(1,30))
f(c(1,50))
check()
check()
check()
check()
check()
#'     If not found, returns NA for each such station.
#'
#' @examples
#' \dontrun{
#' import_ts(ids=c("SX67F051", "SS50F007"), org="EA", dat="gdf",
#'     startDate="2017-01-01", endDate="2017-02-01")
#' import_ts(ids="SX67F051", org="EA", dat="gdf", metadata=T)
#' }
#'
#' @export
importTimeSeries <- function(ids, dat, org = c("NRFA", "EA", "SEPA", "COSMOS"),
startDate = NULL, endDate = NULL, metadata=FALSE,
datetime = TRUE){
ids <- as.character(ids)  #ids for respective dataset, not refs
org <- match.arg(org)
if (!is.null(startDate)) {
startDate <- lubridate::as_datetime(x=startDate,
format=lubridate::guess_formats(startDate, c("dmy", "ymd")),
tz="UTC")[1]
}
if (!is.null(endDate)) {
endDate <- lubridate::as_datetime(x=endDate,
format=lubridate::guess_formats(endDate, c("dmy", "ymd")),
tz="UTC")[1]
}
## should convert likely date strings/objects to date objects
li <- length(ids)
if (li == 0) { stop("Enter valid id for station(s).") }
stationListId <- stationList(org)$id
if (all(!(ids %in% stationListId))) {
# check data available for any stations
stop("No supplied stations available in selected list.")
}
ts <- ts_fetch_internal(ids, org, dat, startDate, endDate)
names(ts) <- ids
if (datetime) { ts <- lapply(ts, function(y){y$data <- reformatTimeSeries(y$data);y}) }
if (!metadata) { ts <- lapply(ts, function(y){y['data',drop=F]}) }
if (li == 1) { ts <- ts[[1]] }
return(ts)
}
#     If not found, returns NA for each such station.
#
# @examples
# \dontrun{
# startDate <- lubridate::as_datetime("1901-01-01")
# endDate <- lubridate::as_datetime("1901-02-01")
# ts_fetch_internal(ids=c("SX67F051", "SS50F007"), org="EA", dat="gdf",
#     startDate=startDate, endDate=endDate)
# }
#
ts_fetch_internal <- function(ids, org, dat, startDate=NULL, endDate=NULL){
# fetches relevant time series and metadata information from API
if (org == "EA") {
refs <- idToRef(ids)
}else{
refs <- ids
}
# generate url to relevant API page
txt <- paste0("https://gateway-staging.ceh.ac.uk/hydrology-ukscape/",
"stations/",org,"/",dat,"/",refs)
if (!is.null(startDate)) {
txt <- paste0(txt,"/",format(startDate, "%Y-%m%-%d"))
# if one date provided only gives that date
if (!is.null(endDate)) {
txt <- paste0(txt,"/",format(endDate, "%Y-%m%-%d"))
}
}
txt <- as.list(txt)
# checks that address works
accesstest <- sapply(txt, function(y){
class(try(jsonlite::fromJSON(txt=y, simplifyDataFrame=T),
silent=T)) != "try-error"
})
if (sum(!accesstest)>0) {
message(paste0("Not possible to access ", dat, " data for stations ",
paste(ids[!accesstest], sep=", "), "."))
}
ts_fetch <- vector("list", length(ids))
# get data from successfully tested stations
ts_fetch[accesstest] <- lapply(txt[accesstest],
jsonlite::fromJSON, simplifyDataFrame=T)
ts_fetch[!accesstest] <- NA
# check for wrong period of time
datatest <- sapply(ts_fetch,
function(y){is.list(y) && is.data.frame(y$data)})
if (sum(!datatest & accesstest) > 0) {
message(paste0("No ", dat, " data for stations ",
paste(ids[!datatest & accesstest], sep=", "),
". Check period selected."))
}
# make all stations have same format
#ts_fetch[!accesstest | !datatest] <- list(list("detail"=NULL, "data"=NULL))
ts_fetch <- replace(ts_fetch,
which(!accesstest | !datatest),
list(list("detail"=NA, "data"=NA)))
#if (length(ts_fetch) == 1) ts_fetch <- ts_fetch[[1]]
return(ts_fetch)
}
View(importTimeSeries)
importTimeSeries("21003", "amax_flow", "NRFA")
lookup_fetch_internal <- function(){
# internal function to call the lookup table from API
# if(exists(lookup_fetch)){
#   return(lookup_fetch)
# }else{
jsonlite::fromJSON(
txt="https://gateway-staging.ceh.ac.uk/hydrology-ukscape/lookup",
simplifyDataFrame=T)
#}
}
station_fetch_internal <- function(){
# internal function to call station list tabel from API
# if(exists(station_fetch)){
#   return(station_fetch)
# }else{
jsonlite::fromJSON(
txt="https://gateway-staging.ceh.ac.uk/hydrology-ukscape/stations",
simplifyDataFrame=T)
#}
}
ST <- station_fetch_internal()
ST$metadata$dataTypes
importTimeSeries("21003", "amax-flow", "NRFA")
ts_fetch_internal(21003, "NRFA", "amax-flow")
ts_fetch_internal(21003, "NRFA", "amax-stage")
ts_fetch_internal(21003, "NRFA", "gdf")
ts_fetch_internal(21004, "NRFA", "gdf")
ts_fetch_internal(21005, "NRFA", "gdf")
ts_fetch_internal(21005, "NRFA", "gdf", startDate="1900-01-01", endDate="2020-12-31")
#     If not found, returns NA for each such station.
#
# @examples
# \dontrun{
# startDate <- lubridate::as_datetime("1901-01-01")
# endDate <- lubridate::as_datetime("1901-02-01")
# ts_fetch_internal(ids=c("SX67F051", "SS50F007"), org="EA", dat="gdf",
#     startDate=startDate, endDate=endDate)
# }
#
ts_fetch_internal <- function(ids, org, dat, startDate=NULL, endDate=NULL){
# fetches relevant time series and metadata information from API
if (org == "EA") {
refs <- idToRef(ids)
}else{
refs <- ids
}
# generate url to relevant API page
txt <- paste0("https://gateway-staging.ceh.ac.uk/hydrology-ukscape/",
"stations/",org,"/",dat,"/",refs)
if (!is.null(startDate)) {
txt <- paste0(txt,"/",format(startDate, "%Y-%m%-%d"))
# if one date provided only gives that date
if (!is.null(endDate)) {
txt <- paste0(txt,"/",format(endDate, "%Y-%m%-%d"))
}
}
txt <- as.list(txt)
# checks that address works
accesstest <- sapply(txt, function(y){
class(try(jsonlite::fromJSON(txt=y, simplifyDataFrame=T),
silent=T)) != "try-error"
})
if (sum(!accesstest)>0) {
message(paste0("Not possible to access ", dat, " data for stations ",
paste(ids[!accesstest], sep=", "), "."))
}
ts_fetch <- vector("list", length(ids))
# get data from successfully tested stations
ts_fetch[accesstest] <- lapply(txt[accesstest],
jsonlite::fromJSON, simplifyDataFrame=T)
ts_fetch[!accesstest] <- NA
# check for wrong period of time
datatest <- sapply(ts_fetch,
function(y){is.list(y) && is.data.frame(y$data)})
if (sum(!datatest & accesstest) > 0) {
message(paste0("No ", dat, " data for stations ",
paste(ids[!datatest & accesstest], sep=", "),
". Check period selected."))
}
# make all stations have same format
#ts_fetch[!accesstest | !datatest] <- list(list("detail"=NULL, "data"=NULL))
ts_fetch <- replace(ts_fetch,
which(!accesstest | !datatest),
list(list("detail"=NA, "data"=NA)))
#if (length(ts_fetch) == 1) ts_fetch <- ts_fetch[[1]]
return(ts_fetch)
}
lookup_fetch_internal <- function(){
# internal function to call the lookup table from API
# if(exists(lookup_fetch)){
#   return(lookup_fetch)
# }else{
jsonlite::fromJSON(
txt="https://gateway-staging.ceh.ac.uk/hydrology-ukscape/lookup",
simplifyDataFrame=T)
#}
}
station_fetch_internal <- function(){
# internal function to call station list tabel from API
# if(exists(station_fetch)){
#   return(station_fetch)
# }else{
jsonlite::fromJSON(
txt="https://gateway-staging.ceh.ac.uk/hydrology-ukscape/stations",
simplifyDataFrame=T)
#}
}
LU <- lookup_fetch_internal()
View(LU)
SF <- station_fetch_internal()
View(SF)
View(SF$metadata$dataTypes
)
View(SF$metadata$dataTypes[[1]])
IM <- importMetadata(ids21005, dat="", org="NRFA")
#' }
#'      If not found, returns NA for each such station.
#'
#' @examples
#' \dontrun{
#' import_metadata(ids=c("SX67F051", "SS50F007"), org="EA", dat="gdf")
#' import_metadata(ids="SX67F051", org="EA", dat="gdf")
#' }
#'
#' @export
importMetadata <- function(ids, dat, org = c("NRFA", "EA", "SEPA", "COSMOS")){
ids <- as.character(ids)  #ids for respective dataset, not refs
org <- match.arg(org)
li <- length(ids)
if (li == 0) { stop("Enter valid id for station(s).") }
stationListId <- stationList(org)$id
if (all(!(ids %in% stationListId))) {
# check data available for any stations
stop("No supplied stations available in selected list.")
}
ts <- ts_fetch_internal(ids, org, dat, startDate=NULL, endDate=NULL)
names(ts) <- ids
ts <- lapply(ts, function(y){y['detail',drop=F]})
if (li == 1) ts <- ts[[1]]
return(ts)
}
IM <- importMetadata(ids21005, dat="", org="NRFA")
IM <- importMetadata(ids=21005, dat="", org="NRFA")
#' @param org organisation to obtain list of stations from.
#'
#' @return dataframe containing station names, ids and other important information.
#'
#' @examples
#' \dontrun{
#' stationList("NRFA")
#' }
#'
#' @export stationList
stationList <- function(org = c("EA", "NRFA", "SEPA", "COSMOS")){
org <- match.arg(org)
listno <- switch(org,
"EA" = 2,
"NRFA" = 1,
"SEPA" = 3,
"COSMOS" = 4)
station_fetch <- station_fetch_internal()
jsonlite::flatten(station_fetch$data[[listno]])
}
IM <- importMetadata(ids=21005, dat="", org="NRFA")
IM <- importMetadata(ids=21005, dat="gdf", org="NRFA")
IM
View(LU)
IM <- importMetadata(ids=76005, dat="gdf", org="NRFA")
IM
IM <- importMetadata(ids=76005, dat="amax-flow", org="NRFA")
IM
ts1 <- ts_fetch_internal(76005, "NRFA", "amax-flow")
ts1
debug(ts_fetch_internal)
ts1 <- ts_fetch_internal(76005, "NRFA", "amax-flow")
txt
txt
ts1 <- ts_fetch_internal(76005, "NRFA", "gdf")
ts1 <- ts_fetch_internal(76005, "NRFA", "gdf", "1900-01-01", "2020-12-31")
#     If not found, returns NA for each such station.
#
# @examples
# \dontrun{
# startDate <- lubridate::as_datetime("1901-01-01")
# endDate <- lubridate::as_datetime("1901-02-01")
# ts_fetch_internal(ids=c("SX67F051", "SS50F007"), org="EA", dat="gdf",
#     startDate=startDate, endDate=endDate)
# }
#
ts_fetch_internal <- function(ids, org, dat, startDate=NULL, endDate=NULL){
# fetches relevant time series and metadata information from API
if (org == "EA") {
refs <- idToRef(ids)
}else{
refs <- ids
}
# generate url to relevant API page
txt <- paste0("https://gateway-staging.ceh.ac.uk/hydrology-ukscape/",
"stations/",org,"/",dat,"/",refs)
if (!is.null(startDate)) {
txt <- paste0(txt,"/",format(startDate, "%Y-%m-%d"))
# if one date provided only gives that date
if (!is.null(endDate)) {
txt <- paste0(txt,"/",format(endDate, "%Y-%m-%d"))
}
}
txt <- as.list(txt)
# checks that address works
accesstest <- sapply(txt, function(y){
class(try(jsonlite::fromJSON(txt=y, simplifyDataFrame=T),
silent=T)) != "try-error"
})
if (sum(!accesstest)>0) {
message(paste0("Not possible to access ", dat, " data for stations ",
paste(ids[!accesstest], sep=", "), "."))
}
ts_fetch <- vector("list", length(ids))
# get data from successfully tested stations
ts_fetch[accesstest] <- lapply(txt[accesstest],
jsonlite::fromJSON, simplifyDataFrame=T)
ts_fetch[!accesstest] <- NA
# check for wrong period of time
datatest <- sapply(ts_fetch,
function(y){is.list(y) && is.data.frame(y$data)})
if (sum(!datatest & accesstest) > 0) {
message(paste0("No ", dat, " data for stations ",
paste(ids[!datatest & accesstest], sep=", "),
". Check period selected."))
}
# make all stations have same format
#ts_fetch[!accesstest | !datatest] <- list(list("detail"=NULL, "data"=NULL))
ts_fetch <- replace(ts_fetch,
which(!accesstest | !datatest),
list(list("detail"=NA, "data"=NA)))
#if (length(ts_fetch) == 1) ts_fetch <- ts_fetch[[1]]
return(ts_fetch)
}
ts1 <- ts_fetch_internal(76005, "NRFA", "gdf", "1900-01-01", "2020-12-31")
as.Date
as.Date("2020-12-31", "%Y-%m-%d")
as.Date("2020-12-31", "%d-%m-%Y")
A <- s.Date("2020-12-31", "%Y-%m-%d")
A <- as.Date("2020-12-31", "%Y-%m-%d")
str(A)
ts1 <- ts_fetch_internal(76005, "NRFA", "gdf", as.Date("1900-01-01"), as.Date("2020-12-31"))
ts1 <- ts_fetch_internal(76005, "NRFA", "gdf", as.Date("195#0-01-01"), as.Date("2020-12-31"))
ts1 <- ts_fetch_internal(76005, "NRFA", "gdf", as.Date("1950-01-01"), as.Date("2020-12-31"))
ts1 <- ts_fetch_internal(76005, "NRFA", "gdf", as.Date("1960-01-01"), as.Date("2020-12-31"))
ts1 <- ts_fetch_internal(76005, "NRFA", "gdf", as.Date("1970-01-01"), as.Date("2020-12-31"))
ts1 <- ts_fetch_internal(76005, "NRFA", "amax-flow", as.Date("1970-01-01"), as.Date("2020-12-31"))
sum(!is.na(ts1$data$value))
